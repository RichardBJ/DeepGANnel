{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e74a62-f24a-4ca8-880d-9b3ebc02b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs successfully on MBP 2024 metal_102 conda environment.\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pymc as pm\n",
    "from pytensor.compile.ops import as_op\n",
    "import arviz as az\n",
    "import pytensor.tensor as pt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "# Suppress PyTorch warnings\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Use CPU instead of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e833e-037b-4d54-b2f2-d08cb118a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "SIZE = 100\n",
    "T=100\n",
    "dt=0.1\n",
    "NUM_SAMPLES = 100\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bab9d9-c4ce-484c-a4fe-75b25dea68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_channel(params, T, dt):\n",
    "    # kc12, kc21, spikeMax, Fnoise, scale, offset, nSpikes, kco1, koc2, ko12, ko21\n",
    "    kc12, kc21, Fnoise, scale, offset,  kco1, koc2, ko12, ko21 = params\n",
    "    \n",
    "    t = torch.arange(0, T, dt)\n",
    "    zero = torch.tensor(0.0)\n",
    "    \n",
    "    # Convert parameters to tensors\n",
    "    kc12 = torch.tensor(kc12)\n",
    "    kc21 = torch.tensor(kc21)\n",
    "    kco1 = torch.tensor(kco1)\n",
    "    koc2 = torch.tensor(koc2)\n",
    "    ko12 = torch.tensor(ko12)\n",
    "    ko21 = torch.tensor(ko21)\n",
    "    Fnoise = torch.tensor(Fnoise)\n",
    "    \"\"\"\n",
    "    nSpikes = torch.tensor(nSpikes, dtype=torch.int32)\n",
    "    spikeMax = torch.tensor(spikeMax)\"\"\"\n",
    "    scale = torch.tensor(scale)\n",
    "\n",
    "    row1 = torch.stack([zero, kc12, zero, zero])\n",
    "    row2 = torch.stack([kc21, zero, kco1, zero])\n",
    "    row3 = torch.stack([zero, koc2, zero, ko12])\n",
    "    row4 = torch.stack([zero,zero,ko21,zero])\n",
    "    \n",
    "    \n",
    "    r1 = torch.sum(row1)\n",
    "    #row1 = torch.stack([1-r1, kc12, zero, zero])\n",
    "    r2 = torch.sum(row2)\n",
    "    #row2 = torch.stack([kc21, 1-r2, kco1, zero])\n",
    "    r3 = torch.sum(row3)\n",
    "    #row3 = torch.stack([zero, koc2, 1-r3, ko12])\n",
    "    r4 = torch.sum(row4)\n",
    "    #row4 = torch.stack([zero, zero, ko21, 1-r4])\n",
    "\n",
    "    def softmax_row(row):\n",
    "        return torch.nn.functional.softmax(row, dim=0)\n",
    "    \n",
    "    row1 = softmax_row(torch.stack([1-r1, kc12, zero, zero]))\n",
    "    row2 = softmax_row(torch.stack([kc21, 1-r2, kco1, zero]))\n",
    "    row3 = softmax_row(torch.stack([zero, koc2, 1-r3, ko12]))\n",
    "    row4 = softmax_row(torch.stack([zero, zero, ko21, 1-r4]))\n",
    "    transition_matrix = torch.stack([row1, row2, row3, row4])\n",
    "    \n",
    "    # Define the transition function\n",
    "    def transition_fn(state):\n",
    "        probs = transition_matrix[state]\n",
    "        return torch.distributions.Categorical(probs=probs).sample()\n",
    "    \n",
    "    # Define the initial state distribution\n",
    "    initial_probs = torch.tensor([0.3, 0.3, 0.2, 0.2])\n",
    "    initial_distribution = torch.distributions.Categorical(probs=initial_probs)\n",
    "    \n",
    "    # Define the Markov chain\n",
    "    states = [initial_distribution.sample().item()]\n",
    "    \n",
    "    for _ in range(T - 1):\n",
    "        states.append(transition_fn(states[-1]).item())\n",
    "    \n",
    "    channels = torch.tensor(states)\n",
    "    channels = torch.where(channels < 2, torch.zeros_like(channels), torch.ones_like(channels))\n",
    "    noise = torch.normal(zero, Fnoise, (SIZE,))\n",
    "    #F = torch.sin(2 * np.pi * t)*Fnoise\n",
    "    #noise =  A + F \n",
    "    return torch.stack([channels, channels * scale + offset + noise], axis=-1)\n",
    "\n",
    "# Example usage\n",
    "kc12=0.1\n",
    "kc21=0.2\n",
    "Fnoise=0.01\n",
    "scale=0.25\n",
    "offset=-0.4\n",
    "kco1=0.5\n",
    "koc=0.25\n",
    "ko12=0.1\n",
    "ko21=0.2 \n",
    "orig_params = [0.1, 0.2, 0.01, 0.25, -0.4,  0.5, 0.25, 0.1, 0.2]\n",
    "\n",
    "channels = sim_channel(orig_params, T, dt)\n",
    "plt.plot(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e820d2-bc14-4931-9e17-d251571dfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (SIZE // 4), 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.permute(0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c9cd9-4c9f-42cd-9cc6-7c957d98b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for the discriminator\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = nn.BCEWithLogitsLoss()(real_output, torch.ones_like(real_output))\n",
    "    fake_loss = nn.BCEWithLogitsLoss()(fake_output, torch.zeros_like(fake_output))\n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235518de-8db8-47d2-b16f-2dc5addb138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the discriminator\n",
    "discriminator = Discriminator()\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3afd1-795a-4f60-b513-ac8b044187cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = torch.stack([sim_channel(orig_params, T, dt) for _ in range(NUM_SAMPLES)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186fe98-a61a-41be-8e08-fea04e9fcbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymc_sim_channel(params, T, dt):\n",
    "    kc12, kc21, Fnoise, scale, offset, kco1, koc2, ko12, ko21 = params\n",
    "    \n",
    "    t = pt.arange(0, T, dt)\n",
    "    zero = torch.tensor(0.0)\n",
    "    \"\"\"\n",
    "    # Convert parameters to NumPy arrays first\n",
    "    kc12 = pm.draw(kc12)\n",
    "    kc21 = pm.draw(kc21)\n",
    "    kco1 = pm.draw(kco1)\n",
    "    koc2 = pm.draw(koc2)\n",
    "    ko12 = pm.draw(ko12)\n",
    "    ko21 = pm.draw(ko21)\n",
    "    #Current version not even using spikes\n",
    "    nSpikes = pm.draw(nSpikes)\n",
    "    spikeMax = pm.draw(spikeMax)\n",
    "    Fnoise = pm.draw(Fnoise)\n",
    "    scale = pm.draw(scale)\n",
    "    offset = pm.draw(offset)\"\"\"\n",
    "    \n",
    "    # Then convert to PyTorch tensors\n",
    "    kc12 = torch.tensor(kc12)\n",
    "    kc21 = torch.tensor(kc21)\n",
    "    kco1 = torch.tensor(kco1)\n",
    "    koc2 = torch.tensor(koc2)\n",
    "    ko12 = torch.tensor(ko12)\n",
    "    ko21 = torch.tensor(ko21)\n",
    "    \"\"\"\n",
    "    nSpikes = torch.tensor(nSpikes, dtype=torch.int32)\n",
    "    spikeMax = torch.tensor(spikeMax)\"\"\"\n",
    "    Fnoise=torch.tensor(Fnoise)\n",
    "    scale = torch.tensor(scale)\n",
    "    offset = torch.tensor(offset)\n",
    "    \n",
    "    \n",
    "    row1 = torch.stack([zero, kc12, zero, zero])\n",
    "    row2 = torch.stack([kc21, zero, kco1, zero])\n",
    "    row3 = torch.stack([zero, koc2, zero, ko12])\n",
    "    row4 = torch.stack([zero, zero, ko21, zero])\n",
    "    \n",
    "    r1 = torch.sum(row1)\n",
    "    #row1 = torch.stack([1-r1, kc12, zero, zero])\n",
    "    r2 = torch.sum(row2)\n",
    "    #row2 = torch.stack([kc21, 1-r2, kco1, zero])\n",
    "    r3 = torch.sum(row3)\n",
    "    #row3 = torch.stack([zero, koc2, 1-r3, ko12])\n",
    "    r4 = torch.sum(row4)\n",
    "    #row4 = torch.stack([zero, zero, ko21, 1-r4])\n",
    "\n",
    "    def softmax_row(row):\n",
    "        return torch.nn.functional.softmax(row, dim=0)\n",
    "    \n",
    "    row1 = softmax_row(torch.stack([1-r1, kc12, zero, zero]))\n",
    "    row2 = softmax_row(torch.stack([kc21, 1-r2, kco1, zero]))\n",
    "    row3 = softmax_row(torch.stack([zero, koc2, 1-r3, ko12]))\n",
    "    row4 = softmax_row(torch.stack([zero, zero, ko21, 1-r4]))\n",
    "            \n",
    "    transition_matrix = torch.stack([row1, row2, row3, row4])\n",
    "    \n",
    "    def transition_fn(state):\n",
    "        probs = transition_matrix[state]\n",
    "        return torch.distributions.Categorical(probs=probs).sample()\n",
    "    \n",
    "    initial_probs = torch.tensor([0.3, 0.3, 0.2, 0.2])\n",
    "    initial_distribution = torch.distributions.Categorical(probs=initial_probs)\n",
    "    \n",
    "    states = [initial_distribution.sample().item()]\n",
    "    \n",
    "    for _ in range(T - 1):\n",
    "        states.append(transition_fn(states[-1]).item())\n",
    "    \n",
    "    channels = torch.tensor(states)\n",
    "    channels = torch.where(channels < 2, torch.zeros_like(channels), torch.ones_like(channels))\n",
    "    noise = torch.normal(zero, Fnoise, (SIZE,))\n",
    "    \n",
    "    res =  torch.stack([channels, channels * scale + offset + noise], axis=-1)\n",
    "    return res.numpy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80392b-6d36-4f70-a82d-b528d4c1dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@as_op(itypes=[pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar,\n",
    "       pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar], otypes=[pt.dvector])\n",
    "def new_pymc_sim_channel(kc12, kc21, Fnoise, scale, offset, kco1, koc2, ko12, ko21, T, dt):\n",
    "    kc12, kc21, Fnoise, scale, offset, kco1, koc2, ko12, ko21 = params\n",
    "    \n",
    "    t = pt.arange(0, T, dt)\n",
    "    zero = torch.tensor(0.0)\n",
    "    \n",
    "    # Then convert to PyTorch tensors\n",
    "    kc12 = torch.tensor(kc12)\n",
    "    kc21 = torch.tensor(kc21)\n",
    "    kco1 = torch.tensor(kco1)\n",
    "    koc2 = torch.tensor(koc2)\n",
    "    ko12 = torch.tensor(ko12)\n",
    "    ko21 = torch.tensor(ko21)\n",
    "\n",
    "    Fnoise=torch.tensor(Fnoise)\n",
    "    scale = torch.tensor(scale)\n",
    "    offset = torch.tensor(offset)\n",
    "    \n",
    "    \n",
    "    row1 = torch.stack([zero, kc12, zero, zero])\n",
    "    row2 = torch.stack([kc21, zero, kco1, zero])\n",
    "    row3 = torch.stack([zero, koc2, zero, ko12])\n",
    "    row4 = torch.stack([zero, zero, ko21, zero])\n",
    "    \n",
    "    r1 = torch.sum(row1)\n",
    "    #row1 = torch.stack([1-r1, kc12, zero, zero])\n",
    "    r2 = torch.sum(row2)\n",
    "    #row2 = torch.stack([kc21, 1-r2, kco1, zero])\n",
    "    r3 = torch.sum(row3)\n",
    "    #row3 = torch.stack([zero, koc2, 1-r3, ko12])\n",
    "    r4 = torch.sum(row4)\n",
    "    #row4 = torch.stack([zero, zero, ko21, 1-r4])\n",
    "\n",
    "    def softmax_row(row):\n",
    "        return torch.nn.functional.softmax(row, dim=0)\n",
    "    \n",
    "    row1 = softmax_row(torch.stack([1-r1, kc12, zero, zero]))\n",
    "    row2 = softmax_row(torch.stack([kc21, 1-r2, kco1, zero]))\n",
    "    row3 = softmax_row(torch.stack([zero, koc2, 1-r3, ko12]))\n",
    "    row4 = softmax_row(torch.stack([zero, zero, ko21, 1-r4]))\n",
    "            \n",
    "    transition_matrix = torch.stack([row1, row2, row3, row4])\n",
    "    \n",
    "    def transition_fn(state):\n",
    "        probs = transition_matrix[state]\n",
    "        return torch.distributions.Categorical(probs=probs).sample()\n",
    "    \n",
    "    initial_probs = torch.tensor([0.3, 0.3, 0.2, 0.2])\n",
    "    initial_distribution = torch.distributions.Categorical(probs=initial_probs)\n",
    "    \n",
    "    states = [initial_distribution.sample().item()]\n",
    "    \n",
    "    for _ in range(T - 1):\n",
    "        states.append(transition_fn(states[-1]).item())\n",
    "    \n",
    "    channels = torch.tensor(states)\n",
    "    channels = torch.where(channels < 2, torch.zeros_like(channels), torch.ones_like(channels))\n",
    "    noise = torch.normal(zero, Fnoise, (SIZE,))\n",
    "    \n",
    "    res =  torch.stack([channels, channels * scale + offset + noise], axis=-1)\n",
    "    return res.numpy() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a206a7-b104-437d-9ff5-7eb87a420e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "from pytensor.compile.ops import as_op\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# Define the custom simulation function\n",
    "@as_op(itypes=[pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar, pt.dscalar], otypes=[pt.dmatrix])\n",
    "def new_pymc_sim_channel(kc12, kc21, Fnoise, scale, offset, kco1, koc2, ko12, ko21, T, dt):\n",
    "    t = np.arange(0, T, dt)\n",
    "    zero = torch.tensor(0.0)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    kc12 = torch.tensor(kc12)\n",
    "    kc21 = torch.tensor(kc21)\n",
    "    kco1 = torch.tensor(kco1)\n",
    "    koc2 = torch.tensor(koc2)\n",
    "    ko12 = torch.tensor(ko12)\n",
    "    ko21 = torch.tensor(ko21)\n",
    "    Fnoise = torch.tensor(Fnoise)\n",
    "    scale = torch.tensor(scale)\n",
    "    offset = torch.tensor(offset)\n",
    "    \n",
    "    row1 = torch.stack([zero, kc12, zero, zero])\n",
    "    row2 = torch.stack([kc21, zero, kco1, zero])\n",
    "    row3 = torch.stack([zero, koc2, zero, ko12])\n",
    "    row4 = torch.stack([zero, zero, ko21, zero])\n",
    "    \n",
    "    r1 = torch.sum(row1)\n",
    "    r2 = torch.sum(row2)\n",
    "    r3 = torch.sum(row3)\n",
    "    r4 = torch.sum(row4)\n",
    "\n",
    "    def softmax_row(row):\n",
    "        return torch.nn.functional.softmax(row, dim=0)\n",
    "    \n",
    "    row1 = softmax_row(torch.stack([1-r1, kc12, zero, zero]))\n",
    "    row2 = softmax_row(torch.stack([kc21, 1-r2, kco1, zero]))\n",
    "    row3 = softmax_row(torch.stack([zero, koc2, 1-r3, ko12]))\n",
    "    row4 = softmax_row(torch.stack([zero, zero, ko21, 1-r4]))\n",
    "            \n",
    "    transition_matrix = torch.stack([row1, row2, row3, row4])\n",
    "    \n",
    "    def transition_fn(state):\n",
    "        probs = transition_matrix[state]\n",
    "        return torch.distributions.Categorical(probs=probs).sample()\n",
    "    \n",
    "    initial_probs = torch.tensor([0.3, 0.3, 0.2, 0.2])\n",
    "    initial_distribution = torch.distributions.Categorical(probs=initial_probs)\n",
    "    \n",
    "    states = [initial_distribution.sample().item()]\n",
    "    \n",
    "    for _ in range(int(T / dt) - 1):\n",
    "        states.append(transition_fn(states[-1]).item())\n",
    "    \n",
    "    channels = torch.tensor(states)\n",
    "    channels = torch.where(channels < 2, torch.zeros_like(channels), torch.ones_like(channels))\n",
    "    noise = torch.normal(zero, Fnoise, (len(channels),))\n",
    "    \n",
    "    res = torch.stack([channels, channels * scale + offset + noise], axis=-1)\n",
    "    return res.numpy()\n",
    "\n",
    "# Define the Bayesian model\n",
    "with pm.Model() as model:\n",
    "    # Priors for parameters\n",
    "    kc21 = pm.Beta('kc21', alpha=2, beta=5)\n",
    "    kc12 = pm.Beta('kc12', alpha=2, beta=5)\n",
    "    kco1 = pm.Beta('kco1', alpha=2, beta=5)\n",
    "    koc2 = pm.Beta('koc2', alpha=2, beta=5)\n",
    "    ko12 = pm.Beta('ko12', alpha=2, beta=5)\n",
    "    ko21 = pm.Beta('ko21', alpha=2, beta=5)\n",
    "    Fnoise = pm.HalfNormal('Fnoise', sigma=1)\n",
    "    scale = pm.HalfNormal('scale', sigma=1)\n",
    "    offset = pm.Normal('offset', mu=0, sigma=1)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    \n",
    "    T = pt.as_tensor_variable(np.float64(100))  # Total time\n",
    "    dt = pt.as_tensor_variable(np.float64(1))  # Time step\n",
    "    \n",
    "    # Likelihood\n",
    "    predicted = pm.Normal('predicted', mu=new_pymc_sim_channel(kc12, kc21, Fnoise, scale, offset, kco1, koc2, ko12, ko21, T, dt), sigma=sigma, observed=channels)\n",
    "      \n",
    "    trace = pm.sample(10000, tune=5000, return_inferencedata=True)\n",
    "\n",
    "# Plot the results\n",
    "az.plot_trace(trace)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the summary of the posterior\n",
    "print(az.summary(trace, var_names=[\"kc12\", \"kc21\", \"Fnoise\", \"scale\", \"offset\", \"kco1\", \"koc2\", \"ko12\", \"ko21\", \"sigma\"]))\n",
    "\"\"\"\n",
    "orig_params = [0.1, 0.2, 0.01, 0.25, -0.4,  0.5, 0.25, 0.1, 0.2]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460eb779-517e-4fc4-be50-ecd7f1e40f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(az.summary(trace, var_names=[\"offset\"])[\"mean\"])\n",
    "toffset = az.summary(trace, var_names=[\"offset\"])[\"mean\"].item()\n",
    "print(toffset)\n",
    "with model:\n",
    "    pred_eval = predicted.eval({\n",
    "        kc12: az.summary(trace, var_names=[\"kc12\"])[\"mean\"].item(),\n",
    "        kc21: az.summary(trace, var_names=[\"kc21\"])[\"mean\"].item(),\n",
    "        Fnoise: az.summary(trace, var_names=[\"Fnoise\"])[\"mean\"].item(),\n",
    "        scale: az.summary(trace, var_names=[\"scale\"])[\"mean\"].item(),\n",
    "        offset: az.summary(trace, var_names=[\"offset\"])[\"mean\"].item(),\n",
    "        kco1: az.summary(trace, var_names=[\"kco1\"])[\"mean\"].item(),\n",
    "        koc2: az.summary(trace, var_names=[\"koc2\"])[\"mean\"].item(),\n",
    "        ko12: az.summary(trace, var_names=[\"ko12\"])[\"mean\"].item(),\n",
    "        ko21: az.summary(trace, var_names=[\"ko21\"])[\"mean\"].item(),\n",
    "        sigma: 0\n",
    "    })\n",
    "\n",
    "plt.plot(pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945aa4e-e18b-48a9-a0c2-9281fad7b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    if epoch > 0:\n",
    "        summary = az.summary(trace)\n",
    "        print(summary)\n",
    "        print(disc_loss)\n",
    "    # Sample from the posterior\n",
    "    with model:\n",
    "        trace = pm.sample(5000, tune=500, chains=8, cores=8)\n",
    "    \n",
    "    # Generate synthetic data using the samples\n",
    "    synthetic_data = []\n",
    "    for i in range(NUM_SAMPLES):\n",
    "        idx = np.random.randint(len(trace))\n",
    "        \n",
    "        posterior = trace.posterior.stack(sample=['chain', 'draw']) \n",
    "        #Concerned order might not be correct so manually doing this\n",
    "        #params = [trace.get_values(param)[idx] for param in model.named_vars.keys() if param != 'likelihood']\n",
    "        # kc12, kc21, spikeMax, Fnoise, scale, offset, nSpikes, kco1, koc2, ko12, ko21\n",
    "        \n",
    "        \"\"\"ikc12 = posterior['kc12'][idx].values\n",
    "        ikc21 = posterior['kc21'][idx].values\n",
    "        ikco1 = posterior['kco1'][idx].values\n",
    "        ikoc2 = posterior['koc2'][idx].values\n",
    "        iko12 = posterior['ko12'][idx].values\n",
    "        iko21 = posterior['ko21'][idx].values\n",
    "        iFnoise = posterior['Fnoise'][idx].values\n",
    "        iscale = posterior['scale'][idx].values\n",
    "        ioffset = posterior['offset'][idx].values\"\"\"\n",
    "        ikc12 = posterior['kc12'].mean().values\n",
    "        ikc21 = posterior['kc21'].mean().values\n",
    "        ikco1 = posterior['kco1'].mean().values\n",
    "        ikoc2 = posterior['koc2'].mean().values\n",
    "        iko12 = posterior['ko12'].mean().values\n",
    "        iko21 = posterior['ko21'].mean().values\n",
    "        iFnoise = posterior['Fnoise'].mean().values\n",
    "        iscale = posterior['scale'].mean().values\n",
    "        ioffset = posterior['offset'].mean().values  \n",
    "        \"\"\"\n",
    "        inSpikes = posterior['nSpikes'][idx].values\n",
    "        ispikeMax = posterior['spikeMax'][idx].values\"\"\"\n",
    "        \n",
    "        #kc12, kc21, spikeMax, Fnoise, scale, offset, nSpikes, kco1, koc2, ko12, ko21 = params\n",
    "        params = [ikc12, ikc21, iFnoise, iscale, ioffset, ikco1, ikoc2, iko12, iko21]\n",
    "        strip = pymc_sim_channel(params, T, dt)\n",
    "        #synthetic_data.append(strip.clone().detach().to(dtype=torch.float32))\n",
    "        synthetic_data.append(torch.from_numpy(strip).float())\n",
    "    synthetic_data = torch.stack(synthetic_data)\n",
    "    \n",
    "    # Train discriminator\n",
    "    for _ in range(5):  # Train discriminator more than generator\n",
    "        real_output = discriminator(real_data)\n",
    "        fake_output = discriminator(synthetic_data)\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        discriminator_optimizer.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "    # Update the model's posterior using the discriminator's feedback\n",
    "    with model:\n",
    "        pm.set_data({'discriminator_output': fake_output.mean().item()})\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d92e9-b19e-4bec-88c5-1d5ce7bbdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "with model:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ecf53-352f-41cc-bc11-a9864d756119",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = az.summary(trace)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63429e57-76e0-49bc-b980-83790420c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting parameter names\n",
    "parameter_names = summary.index.tolist()\n",
    "\n",
    "# Iterating through parameter names\n",
    "params=[]\n",
    "for i, param in enumerate(parameter_names):\n",
    "    mean_value = summary.loc[param, 'mean']\n",
    "    params.append(mean_value)\n",
    "    print(f\"Parameter: {param}, Mean: {mean_value}\")\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a09bd-00a0-41ad-8914-cffda163b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim_channel([params[1],params[2],params[3],params[4],params[5],params[0]],T,dt))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d6339-9dd7-4ce2-a2b8-96e9bc5b3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9eefb-b48d-4757-b44e-f09c338bf09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
