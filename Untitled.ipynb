{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a69738-666e-44ee-b85e-0b3ab1e53e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728557585.117679   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728557585.153007   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728557585.153077   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728557585.155395   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728557585.155477   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728557585.155505   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728557585.374772   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728557585.374853   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 11:53:05.374864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728557585.374913   14736 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 11:53:05.374933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22200 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:15:00.0, compute capability: 7.5\n",
      "/home/rbj/miniconda3/envs/env101/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "Model converted and saved for TensorFlow.js at: json_model/tfjs_model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "\n",
    "# Step 2: Convert the Keras model to TensorFlow.js format\n",
    "tfjs_target_dir = \"json_model/tfjs_model\"\n",
    "tfjs.converters.save_keras_model(model, tfjs_target_dir)\n",
    "\n",
    "print(f\"Model converted and saved for TensorFlow.js at: {tfjs_target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b023017-eab8-465b-af53-263787fd7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_weights', 'optimizer_weights']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(\"model.h5\", \"r\") as f:\n",
    "    print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4090c-8d23-4eb7-8823-19ba60e12078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
