{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff37764-5992-40b1-8127-f829f8fabf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entirely untested. Like that'll work!\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.run_functions_eagerly(True)\n",
    "size=200\n",
    "parquet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfa9f4-0706-4940-8b5e-70b9f9a51137",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1  # Number of channels\n",
    "dt = tf.constant(0.1, dtype=tf.float32)\n",
    "T = tf.constant(size, dtype=tf.int32)  # In sample points :-)\n",
    "#Must be a multiple of 2!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36c0af-f3ee-4923-9e88-e5c7b9d73e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def tf_relaxation(binary_sequence, half_life=4.0, relaxation_amount=0.2):\n",
    "    \"\"\"\n",
    "    Apply exponential relaxation to a 1D binary sequence using vectorized TensorFlow operations.\n",
    "    Kind of works backward to what you might think.  Where amp i1 1 and relaxation 0f 0.5 is too 0.5 therefore\n",
    "    relaxation -0.5 is 0 to 1 but it then slowly rising to 1.5\n",
    "    Args:\n",
    "    binary_sequence: tf.Tensor, shape [time_steps], sequence of 0s and 1s\n",
    "    half_life: float, the half-life of the exponential decay\n",
    "    relaxation_amount: float, the amount of relaxation (positive or negative)\n",
    "    Kind of works backward to what you might think.  Where amp i1 1 and relaxation 0f 0.5 is too 0.5 therefore\n",
    "    relaxation -0.5 is 0 to 1 but it then slowly rising to 1.5\n",
    "    Returns:\n",
    "    tf.Tensor, shape [time_steps]\n",
    "    \"\"\"\n",
    "    # Convert input to float32\n",
    "    binary_sequence = tf.cast(binary_sequence, tf.float32)\n",
    "    \n",
    "    # Calculate decay rate\n",
    "    decay_rate = tf.math.log(2.0) / half_life\n",
    "    \n",
    "    # Find the indices where steps occur\n",
    "    steps = tf.not_equal(binary_sequence[1:] - binary_sequence[:-1], 0)\n",
    "    step_indices = tf.where(steps)[:, 0]\n",
    "    \n",
    "    # Calculate the time since each step\n",
    "    time_steps = tf.range(tf.shape(binary_sequence)[0], dtype=tf.float32)\n",
    "    time_since_step = time_steps[:, tf.newaxis] - tf.cast(step_indices, tf.float32)\n",
    "    \n",
    "    # Calculate the exponential decay for each step\n",
    "    decay = tf.exp(-decay_rate * tf.maximum(time_since_step, 0.0))\n",
    "    \n",
    "    # Calculate the relaxation effect\n",
    "    step_values = tf.gather(binary_sequence, step_indices + 1) - tf.gather(binary_sequence, step_indices)\n",
    "    relaxation_effect = relaxation_amount * step_values * decay\n",
    "    \n",
    "    # Sum the effects of all steps\n",
    "    total_relaxation = tf.reduce_sum(relaxation_effect, axis=1)\n",
    "    \n",
    "    # Add the relaxation to the original sequence\n",
    "    relaxed_sequence = binary_sequence + total_relaxation\n",
    "    \n",
    "    return relaxed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45183fe0-b457-435d-9e8b-00bb39720a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def normalize_row(row):\n",
    "    # Find non-zero elements\n",
    "    non_zero_mask = tf.not_equal(row, 0.0)\n",
    "    non_zero_sum = tf.reduce_sum(tf.boolean_mask(row, non_zero_mask))\n",
    "    \n",
    "    # Normalize only non-zero elements\n",
    "    normalized_row = tf.where(\n",
    "        non_zero_mask,\n",
    "        row / non_zero_sum,\n",
    "        row\n",
    "    )      \n",
    "    return normalized_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd5fea-670c-4dec-bb8b-2d265bc9f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is only going to work properly with n = 1 and it's slow.\n",
    "@tf.function(experimental_compile=True)\n",
    "def sim_channel(params, num_steps=T):\n",
    "    pc12, pc21, relaxation, Fnoise, scale, offset, relaxT, pco1, poc2, po12, po21 = params\n",
    "    zero = tf.constant(0.0, dtype=tf.float32)\n",
    "    \n",
    "    unnormalized_matrix = tf.stack([\n",
    "         #s0     #s1  #s2   #s3\n",
    "        [1-pc12, pc12, zero,   zero],          # state 0 CLOSED\n",
    "        [pc21, 1-pc21-pco1, pco1, zero],   # state 1 CLOSED\n",
    "        [zero, poc2, 1-poc2-po12, po12],   # state 2 OPEN\n",
    "        [zero,    zero,   po21, 1-po21]        # state 3 OPEN\n",
    "    ])\n",
    "    \n",
    "    # Normalize each row while preserving zero probabilities\n",
    "    transition_matrix = tf.map_fn(normalize_row, unnormalized_matrix)\n",
    "\n",
    "    initial_distribution = tfp.distributions.Categorical(probs=[0.3, 0.3, 0.2, 0.2])\n",
    "    \n",
    "    markov_chain = tfp.distributions.MarkovChain(\n",
    "        initial_state_prior=initial_distribution,\n",
    "        transition_fn=lambda _, state: tfp.distributions.Categorical(probs=tf.gather(transition_matrix, state)),\n",
    "        num_steps=num_steps\n",
    "    )\n",
    "    states = markov_chain.sample()\n",
    "    #Assuming we have one channel so emission is...\n",
    "    emissions = tf.where(tf.less(states, 2), tf.zeros_like(states), tf.ones_like(states))\n",
    "\n",
    "    channels = tf.cast(emissions, dtype=tf.float32)\n",
    "    # Generate pink noise\n",
    "    white_noise = tf.random.normal(shape=[T])\n",
    "    fft_len = T // 2 + 1\n",
    "    f = tf.range(1, fft_len, dtype=tf.float32)\n",
    "    spectrum = 1.0 / tf.sqrt(f)\n",
    "    spectrum = tf.concat([tf.constant([1.0]), spectrum], axis=0)\n",
    "    white_noise_fft = tf.signal.rfft(white_noise)\n",
    "    pink_noise_fft = white_noise_fft * tf.cast(spectrum, tf.complex64)\n",
    "    pink_noise = tf.signal.irfft(pink_noise_fft)\n",
    "    pink_noise -= tf.reduce_mean(pink_noise)\n",
    "    pink_noise = pink_noise / tf.math.reduce_std(pink_noise)\n",
    "    noise = pink_noise * Fnoise\n",
    "\n",
    "    # Add relaxation\n",
    "    modified_raw_column = (channels * scale) + offset\n",
    "    modified_raw_column = tf_relaxation(modified_raw_column, half_life=relaxT, relaxation_amount=relaxation)\n",
    "    \n",
    "    modified_raw_column += noise\n",
    "\n",
    "    # Combine channels and modified raw column\n",
    "    image = tf.stack([channels, modified_raw_column], axis=1)\n",
    "    \n",
    "    # Final safeguard against NaN values\n",
    "    image = tf.where(tf.math.is_nan(image), tf.zeros_like(image), image)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b759cb-7340-47f2-a241-346b3f8e145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the exponential distribution\n",
    "num_samples = 500\n",
    "saveSim=True\n",
    "\"\"\"pc12, pc21, relaxation, Fnoise, scale, offset, relaxT, pco1, poc2, po12, po21\"\"\"\n",
    "pc12 = tf.constant(.3, dtype=tf.float32)  # Decreased from 0.1\n",
    "pc21 = tf.constant(.8, dtype=tf.float32)  # Decreased from 0.1\n",
    "pco1 = tf.constant(0.3, dtype=tf.float32)  # Decreased from 0.01\n",
    "poc2 = tf.constant(1e-1, dtype=tf.float32)  # Decreased from 0.0001\n",
    "po12 = tf.constant(0.8, dtype=tf.float32)  # Decreased from 0.01\n",
    "po21 = tf.constant(1e-1, dtype=tf.float32)\n",
    "\n",
    "\n",
    "relaxation = tf.constant(0.5, dtype=tf.float32)\n",
    "Fnoise = tf.constant(.04, dtype=tf.float32)\n",
    "SCALE = tf.constant(.6, dtype=tf.float32)\n",
    "#And an offset\n",
    "OFFSET = tf.constant(-0.4, dtype=tf.float32)\n",
    "relaxT=25\n",
    "# nE = tf.constant(200, dtype=tf.int32) #number of events\n",
    "\n",
    "\n",
    "# Generate training data\n",
    "training_data = []\n",
    "lens=[]\n",
    "saver=[]\n",
    "\"\"\"Actually replace \"Anoise\" with relaxation later\"\"\"\n",
    "for sample in tqdm(range(num_samples)):   \n",
    "    params = tf.stack([pc12, pc21, relaxation, Fnoise, SCALE, OFFSET, relaxT, pco1, poc2, po12, po21])  # Use tf.stack instead of tf.constant\n",
    "    segment = sim_channel(params, n=n)\n",
    "    lens.append(sum(abs(segment)))\n",
    "    training_data.append(segment)\n",
    "    if saveSim:\n",
    "        saver.extend(segment)\n",
    "print(f\"Average duration was {sum(lens)/len(lens)}\")\n",
    "if saveSim:\n",
    "    time_col = np.arange(0, len(saver) * dt, dt)\n",
    "    np_data = np.column_stack((time_col, np.asarray(saver) ))\n",
    "    #May have to untensorflow this output\n",
    "    # Convert to a pandas DataFrame\n",
    "    df = pd.DataFrame(np_data, columns=['Time', \n",
    "                                              'Channels', \n",
    "                                              'Noisy Current'])\n",
    "    if parquet:\n",
    "        df.to_parquet(\"regularSimv10Moon.parquet\", index=False)\n",
    "    else:\n",
    "        df.to_csv(\"regularSimv10Moon.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
